# Image Description Toolkit

An AI-powered toolkit for generating descriptive text from images using local language models via Ollama. The toolkit provides a unified workflow system that orchestrates the entire pipeline from video frame extraction through HTML report generation, making it simple to process large collections of media files.

## ğŸŒŸ Features

- **ğŸ”„ Unified Workflow System**: Complete pipeline from video â†’ frames â†’ images â†’ descriptions â†’ HTML reports
- **ğŸ¤– AI-Powered Descriptions**: Generate natural language descriptions using local Ollama models
- **âš¡ Enhanced ONNX Provider**: YOLOv8x object detection + Ollama hybrid workflow for maximum accuracy
- **ğŸ¯ Spatial Object Detection**: Precise location analysis (top/middle/bottom + left/center/right) and size classification
- **ğŸ§ª Comprehensive Model Testing**: Automatically test all available Ollama models with all prompt styles to find optimal combinations
- **ğŸ“Š Advanced Performance Analytics**: Detailed reporting with timing, success rates, and quality metrics across all model/prompt combinations
- **ğŸ¥ Video Frame Extraction**: Extract frames from videos for analysis
- **ğŸ–¼ï¸ Image Format Conversion**: Convert HEIC images to JPG automatically
- **ğŸ“„ HTML Report Generation**: Create beautiful web galleries with descriptions
- **âš¡ Batch Processing**: Handle multiple files and directories efficiently
- **ğŸ“± Interactive Visual Reports**: Comprehensive HTML reports with side-by-side model comparisons
- **ğŸ“‹ Professional Logging**: Complete logging with statistics and progress tracking
- **ğŸ› ï¸ Individual Script Access**: Use components separately when needed

## ğŸ“ Support & Documentation

- **âš¡ Enhanced ONNX Guide**: See `docs/ENHANCED_ONNX_GUIDE.md` for YOLOv8x + Ollama integration details
- **ğŸ“‹ Comprehensive Testing Guide**: See `TESTING_GUIDE.md` for complete model testing documentation
- **ğŸ“š Documentation**: Detailed guides available in the `docs/` directory
- **ğŸ› Issues**: Report bugs or request features via [GitHub Issues](https://github.com/kellylford/Image-Description-Toolkit/issues)
- **ğŸ’¬ Discussions**: Join conversations in [GitHub Discussions](https://github.com/kellylford/Image-Description-Toolkit/discussions)
- **ğŸ§ª Testing**: Run `cd tests && python run_tests.py` to verify your setup

## ğŸš€ **Ready to Get Started?**

### Option 1: Automated Setup (Recommended)
```cmd
# Windows users - run the automated setup script
setup.bat
```

### Option 2: Manual Setup
```bash
# 1. Install dependencies (includes YOLO detection)
pip install -r requirements.txt

# 2. Install Ollama and pull a vision model  
ollama pull llava:7b

# 3. Test your setup
cd tests && python run_tests.py

# 4. Find the best model for your images (recommended)
python comprehensive_test.py tests/test_files/images

# 5. Process your first media collection
python workflow.py path/to/your/media/files

# 6. Check the timestamped output directory for results!

# âœ¨ Bonus: Resume interrupted workflows
python workflow.py --resume workflow_output_directory
```

**ğŸ‰ That's it!** The workflow system will handle the rest automatically. 

**ğŸ“‹ For detailed setup instructions, see [QUICK_START.md](QUICK_START.md)**

**ğŸ’¡ Pro Tip**: Always run the comprehensive testing first to discover which models work best with your specific types of images. You might be surprised which models perform excellently!

## ğŸ”§ System Requirements

**Ollama is required for vision model inference and must be installed and running for the toolkit to function.**

### âš¡ **Copilot+ PC High-Performance Setup** (Recommended)

**For fastest performance with NPU acceleration:**

1. **Hardware Requirements**:
   - NPU with 40+ TOPS (AMD Ryzen AI 300, Intel Core Ultra 200V, Snapdragon X)
   - Windows 11 (22H2 or later)
   - 16GB+ RAM

2. **Quick Setup**:
   ```bash
   # Run the automated setup script
   setup_windows.bat
   
   # Or verify existing setup
   python verify_system.py
   ```

3. **Performance Results**:
   - **<100ms response times** with NPU acceleration
   - **5-10x more detailed** descriptions than standard AI
   - **Completely local** - no internet required after setup
   - **Professional quality** image analysis

**ğŸ“‹ See [COPILOT_PC_SETUP_GUIDE.md](COPILOT_PC_SETUP_GUIDE.md) for detailed Copilot+ PC installation guide.**

### Install Ollama

**macOS/Linux:**
```bash
curl -fsSL https://ollama.ai/install.sh | sh
```

**Windows:**
Download and install from [https://ollama.ai/download/windows](https://ollama.ai/download/windows)

### Start Ollama Server

```bash
ollama serve
```

### Verify Ollama is Running

```bash
curl http://localhost:11434/api/version
```

If Ollama is running properly, you should see a JSON response with version information.

**âš ï¸ Important**: The Image Description Toolkit will not function unless Ollama is installed and running. Make sure to start the Ollama server before using any of the toolkit's AI-powered features.

## ğŸ“ Project Structure

```
Image-Description-Toolkit/
â”œâ”€â”€ setup.bat                 # ğŸ”§ Automated setup script (Windows)
â”œâ”€â”€ QUICK_START.md            # ğŸ“‹ Quick setup guide
â”œâ”€â”€ workflow.py               # ğŸ¯ Main entry point - workflow wrapper
â”œâ”€â”€ comprehensive_test.py     # ğŸ§ª Comprehensive model testing and comparison
â”œâ”€â”€ scripts/                  # ğŸ”§ Core processing scripts
â”‚   â”œâ”€â”€ workflow.py           #    Workflow orchestrator (main engine)
â”‚   â”œâ”€â”€ video_frame_extractor.py #    Extract frames from videos
â”‚   â”œâ”€â”€ ConvertImage.py       #    Convert HEIC to JPG
â”‚   â”œâ”€â”€ image_describer.py    #    AI image description
â”‚   â”œâ”€â”€ descriptions_to_html.py #    Generate HTML reports
â”‚   â”œâ”€â”€ workflow_utils.py     #    Workflow utilities
â”‚   â”œâ”€â”€ workflow_config.json  #    Workflow configuration
â”‚   â”œâ”€â”€ image_describer_config.json # AI model settings
â”‚   â””â”€â”€ video_frame_extractor_config.json # Video processing config
â”œâ”€â”€ docs/                     # ğŸ“š Documentation
â”œâ”€â”€ tests/                    # ğŸ§ª Test suite and test files
â”œâ”€â”€ TESTING_GUIDE.md          # ğŸ“‹ Comprehensive testing documentation
â”œâ”€â”€ requirements.txt          # ğŸ“¦ Python dependencies
â”œâ”€â”€ .gitignore               # ğŸš« Git ignore rules
â””â”€â”€ README.md                # ğŸ“– This file
```

## ğŸš€ Quick Start

### Primary Usage (Recommended)

The **workflow system** is the main way to use this toolkit:

```bash
# 1. Install dependencies
pip install -r requirements.txt

# 2. Install Ollama and a vision model
# Download from https://ollama.ai/
ollama pull llava:7b  # or llama3.2-vision:11b, moondream, etc.

# 3. Process your media files (videos + images)
python workflow.py path/to/your/media

# 4. Find results in timestamped output directory
# -> workflow_output_YYYYMMDD_HHMMSS/
```

### Model Testing & Optimization (New!)

Before processing large collections, use the comprehensive testing system to find the optimal AI model for your needs:

```bash
# Test all available models with all prompt styles
python comprehensive_test.py path/to/sample/images

# Generates detailed reports:
# - comprehensive_test_visual_report.html (interactive comparison)
# - comprehensive_test_data.csv (spreadsheet analysis)
# - test_statistics.txt (performance analytics)
# - failure_analysis.txt (troubleshooting)
```

This powerful testing capability:
- **Discovers all installed Ollama models** (not just vision-labeled ones)
- **Tests every model/prompt combination** through the complete workflow
- **Generates comprehensive performance analytics** with timing and success rates
- **Creates interactive HTML reports** for visual model comparison
- **Provides data-driven model selection** based on your specific images

### GUI Application (Project Management)

For ongoing project management and iterative description work:

```bash
# Launch the ImageDescriber GUI
cd imagedescriber
python imagedescriber.py

# Features:
# - Create/save/load workspace projects (.idw files)
# - Batch processing with enterprise-level controls  
# - Advanced filtering (all/described/batch/videos)
# - Full keyboard navigation (R/F2=rename, P=process, B=batch)
# - Support for both Ollama local and OpenAI cloud AI
```

### Workflow Steps

The workflow automatically handles:
1. **Video Processing** â†’ Extract frames from MP4, MOV, AVI files  
2. **Image Conversion** â†’ Convert HEIC to JPG  
3. **AI Description** â†’ Generate descriptions using Ollama models  
4. **HTML Generation** â†’ Create beautiful web gallery with descriptions

### Advanced Workflow Usage

```bash
# Process only specific steps
python workflow.py media/ --steps describe,html

# Use custom output directory
python workflow.py media/ --output-dir my_results

# Override AI model
python workflow.py media/ --model llama3.2-vision:11b

# Dry run (see what would be processed)
python workflow.py media/ --dry-run

# Verbose logging
python workflow.py media/ --verbose
```

### Individual Script Usage (Advanced)

When you need fine-grained control, you can use scripts directly:

```bash
# Video frame extraction
cd scripts
python video_frame_extractor.py path/to/videos

# Image format conversion  
python ConvertImage.py path/to/heic/files --output converted/

# AI image descriptions
python image_describer.py path/to/images --model llava:7b

# HTML report generation
python descriptions_to_html.py descriptions.txt report.html
```

## ğŸ§ª Testing

### Comprehensive Model Testing

Run the comprehensive testing system to evaluate all available models:

```bash
# Test all models with sample images
python comprehensive_test.py tests/test_files/images

# Custom output directory
python comprehensive_test.py sample_images/ --output-dir my_test_results
```

The testing system generates multiple report formats:
- **Interactive HTML report** - Visual comparison of all models and prompts
- **CSV data** - Raw performance data for spreadsheet analysis  
- **Performance statistics** - Model timing and success rate analytics
- **Failure analysis** - Detailed troubleshooting information

See `TESTING_GUIDE.md` for complete testing documentation.

### Basic Testing

```bash
# Run test suite
cd tests
python run_tests.py

# Test individual components
python test_workflow.py
```

## ğŸ› ï¸ Core Components

### Comprehensive Testing System (`comprehensive_test.py`) **NEW!**
Advanced model evaluation and comparison system:
- **ğŸ¤– Model Discovery**: Automatically finds all installed Ollama models (including non-vision models like gemma2)
- **ğŸ“Š Complete Testing**: Tests every model with every prompt style through the full 4-step workflow
- **ğŸ“ˆ Performance Analytics**: Detailed timing, success rates, and failure analysis
- **ğŸ“‹ Multiple Report Formats**: Interactive HTML, CSV data, statistics, and failure reports  
- **ğŸ¯ Data-Driven Selection**: Make informed decisions about which models work best for your images
- **ğŸ’¡ Model Discovery**: Often reveals that non-vision models work excellently for image descriptions

### Workflow System (`workflow.py` â†’ `scripts/workflow.py`)
The main orchestrator that provides a unified processing pipeline:
- **ğŸ¯ Simple Entry Point**: Just run `python workflow.py media_folder`
- **ğŸ”„ Complete Pipeline**: Handles videoâ†’framesâ†’conversionâ†’descriptionsâ†’HTML
- **ğŸ“Š Progress Tracking**: Real-time logging with comprehensive statistics  
- **ğŸ›¡ï¸ Error Resilience**: Continues processing despite individual file failures
- **âš™ï¸ Flexible Configuration**: Support for custom models, output directories, and step selection
- **ğŸ“‹ Professional Logging**: Timestamped logs with detailed statistics and summaries

### Video Frame Extractor (`scripts/video_frame_extractor.py`)
Extract frames from videos for image analysis:
- **ğŸ¬ Multiple Formats**: MP4, MOV, AVI, MKV support
- **â±ï¸ Flexible Extraction**: Time-based intervals (e.g., every 5 seconds)
- **ğŸ–¼ï¸ Quality Control**: Configurable resolution and image quality
- **ğŸ“ Organized Output**: Systematic frame numbering and folder structure

### Image Converter (`scripts/ConvertImage.py`)  
Convert HEIC images to JPG for broader compatibility:
- **ğŸ“± HEIC/HEIF Support**: Handle iPhone/iOS photos seamlessly
- **ğŸ”§ Quality Controls**: Configurable compression settings  
- **ğŸ“‹ Metadata Preservation**: Maintains EXIF data during conversion
- **âš¡ Batch Processing**: Convert entire directories efficiently

### AI Image Describer (`scripts/image_describer.py`)
Generate natural language descriptions using local Ollama models:
- **ğŸ¤– Multiple Models**: llava:7b, llama3.2-vision:11b, moondream, bakllava
- **ğŸ’¬ Custom Prompts**: Configurable description styles (detailed, brief, technical)
- **ğŸ  Local Processing**: No cloud dependencies, complete privacy
- **ğŸ“Š EXIF Integration**: Include camera settings, GPS, timestamps in output
- **ğŸ§  Memory Optimization**: Smart processing for large image collections

### ImageDescriber GUI (`imagedescriber/imagedescriber.py`)
Professional graphical interface for managing image description projects:
- **ğŸ“ Workspace System**: Save/load projects as `.idw` files for long-term management
- **ğŸ¯ Batch Processing**: Enterprise-level controls for processing multiple images
- **ğŸ” Advanced Filtering**: View all, described, batch-marked, or videos-only items
- **â™¿ Accessibility**: WCAG-compliant design with full keyboard navigation and screen reader support  
- **âŒ¨ï¸ Keyboard Shortcuts**: R/F2 for rename, P for process, B for batch marking
- **ğŸ“ Rename Functionality**: Custom display names within workspace (files unchanged)
- **ğŸ¥ Video Support**: Frame extraction and management integrated
- **ğŸ“Š Real-time Status**: Live processing indicators and description counts
- **ğŸŒ Dual AI Support**: Both Ollama local and OpenAI cloud providers
- **âš¡ Enhanced ONNX Provider**: YOLOv8x object detection + Ollama hybrid workflow

### Enhanced ONNX Provider (`imagedescriber/ai_providers.py`) **NEW!**
Advanced AI provider combining YOLO object detection with Ollama language models:
- **ğŸ¯ YOLOv8x Integration**: Maximum accuracy object detection (130MB model)
- **ğŸ“ Spatial Analysis**: Precise object location (top/middle/bottom + left/center/right)
- **ğŸ“ Size Classification**: Object size analysis (large/medium/small/tiny)
- **ğŸ”„ Hybrid Workflow**: YOLO detection â†’ Enhanced prompts â†’ Ollama descriptions
- **ğŸ·ï¸ Model Labeling**: Shows "YOLO Enhanced" suffix on Ollama models
- **ğŸ›ï¸ Hardware Acceleration**: Uses available hardware (GPU/NPU) when possible
- **ğŸ“Š Enhanced Prompts**: Includes detected object data for more accurate descriptions
- **ğŸ”§ Diagnostic Tools**: Description Properties feature for troubleshooting

### HTML Report Generator (`scripts/descriptions_to_html.py`)
Create beautiful web galleries from descriptions:
- **ğŸŒ Responsive Design**: Mobile-friendly layouts
- **ğŸ¨ Professional Styling**: Clean, modern web interface
- **ğŸ” Interactive Features**: Easy browsing and navigation

## âš™ï¸ Configuration

Configuration files are located in the `scripts/` directory:

- **`scripts/workflow_config.json`** - Main workflow settings, step configuration, and output preferences
- **`scripts/image_describer_config.json`** - AI model selection, prompts, and processing parameters  
- **`scripts/video_frame_extractor_config.json`** - Video processing settings and frame extraction options

### Example Workflow Configuration

```json
{
  "workflow": {
    "default_steps": ["video", "convert", "describe", "html"],
    "steps": {
      "video_extraction": {
        "config_file": "video_frame_extractor_config.json"
      },
      "image_conversion": {
        "quality": 95,
        "keep_metadata": true
      },
      "image_description": {
        "model": "llava:7b",
        "prompt_style": "detailed",
        "config_file": "image_describer_config.json"
      },
      "html_generation": {
        "title": "Image Analysis Report",
        "include_details": false
      }
    }
  }
}
```

## ğŸ”§ Advanced Usage

### Model Testing and Selection

```bash
# Comprehensive model testing (recommended first step)
python comprehensive_test.py /path/to/sample/images

# View results in generated HTML report
# Open: comprehensive_test_YYYYMMDD_HHMMSS/comprehensive_test_visual_report.html

# Analyze performance data in spreadsheet
# Import: comprehensive_test_YYYYMMDD_HHMMSS/comprehensive_test_data.csv
```

### Workflow Examples

```bash
# Process entire media collection (videos + images)
python workflow.py /path/to/media/collection

# Only generate descriptions and HTML (skip video/conversion)
python workflow.py /path/to/images --steps describe,html

# Use different AI model (based on testing results)
python workflow.py /path/to/images --model llama3.2-vision:11b

# Custom output location
python workflow.py /path/to/images --output-dir /custom/output/path

# Preview what will be processed
python workflow.py /path/to/images --dry-run

# Get detailed logging
python workflow.py /path/to/images --verbose
```

### Custom AI Models

```bash
# Install additional Ollama models
ollama pull llama3.2-vision:11b  # Larger, more capable model
ollama pull moondream:latest     # Lightweight alternative
ollama pull bakllava:latest      # Another vision model option

# Update scripts/image_describer_config.json to use your preferred model
```

### Output Structure

When you run the workflow, it creates a timestamped output directory:

```
workflow_output_20250721_143022/
â”œâ”€â”€ logs/                     # Detailed processing logs
â”‚   â”œâ”€â”€ workflow_orchestrator_20250721_143022.log
â”‚   â”œâ”€â”€ video_frame_extractor_20250721_143023.log
â”‚   â”œâ”€â”€ image_converter_20250721_143024.log
â”‚   â””â”€â”€ image_describer_20250721_143025.log
â”œâ”€â”€ extracted_frames/         # Video frames (if processing videos)
â”œâ”€â”€ converted_images/         # HEICâ†’JPG conversions (if needed)
â”œâ”€â”€ descriptions/            # AI-generated descriptions
â”‚   â””â”€â”€ image_descriptions.txt
â””â”€â”€ reports/                 # HTML reports
    â””â”€â”€ image_descriptions.html
```

## ğŸ¤ Contributing

We welcome contributions! Here's how to get started:

1. **Fork the repository**
2. **Create a feature branch**: `git checkout -b feature/amazing-feature`
3. **Install development dependencies**: `pip install -r requirements.txt`
4. **Test your setup**: `cd tests && python run_tests.py`
5. **Make your changes**
6. **Test the workflow**: `python workflow.py tests/test_files/ --dry-run`
7. **Update documentation** if needed
8. **Submit a pull request**

### Development Guidelines
- Follow PEP 8 style guidelines
- Add tests for new functionality  
- Ensure the workflow system continues to work end-to-end
- Update documentation for new features
- Test with multiple Python versions (3.8+)

## ğŸ“ Support & Documentation

- **ï¿½ Documentation**: Detailed guides available in the `docs/` directory
- **ğŸ› Issues**: Report bugs or request features via [GitHub Issues](https://github.com/kellylford/Image-Description-Toolkit/issues)
- **ï¿½ Discussions**: Join conversations in [GitHub Discussions](https://github.com/kellylford/Image-Description-Toolkit/discussions)
- **ğŸ§ª Testing**: Run `cd tests && python run_tests.py` to verify your setup

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

## ï¿½ **Ready to Get Started?**

```bash
# 1. Install dependencies
pip install -r requirements.txt

# 2. Install Ollama and pull a vision model  
ollama pull llava:7b

# 3. Test your setup
cd tests && python run_tests.py

# 4. Process your first media collection
python workflow.py path/to/your/media/files

# 5. Check the timestamped output directory for results!
```

**ğŸ‰ That's it!** The workflow system will handle the rest automatically.
