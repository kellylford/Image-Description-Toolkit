# Image Description Model Selection Guide

## Overview

The Image Description Toolkit supports multiple AI providers with dozens of vision models. This guide helps you choose the best model for your specific needs, considering factors like speed, quality, resource usage, and prompt-following ability.

## Quick Recommendations

### üöÄ **Just Getting Started?**
- **Ollama**: `moondream:latest` (fast, lightweight, good quality)
- **Hugging Face**: `microsoft/git-base-coco` (smallest, honest basic captions)

### üéØ **Best Overall Balance?**
- **Ollama**: `llava-llama3:latest` (excellent quality, reasonable speed)
- **Hugging Face**: ‚ö†Ô∏è **Wait for instructblip download** (blip2-opt disappoints)

### üèÜ **Highest Quality?**
- **OpenAI**: `gpt-4o` (best overall, requires API key)
- **Ollama**: `llama3.2-vision:latest` (excellent free option)

### ‚ùå **Models to Avoid**
- **Hugging Face**: `Salesforce/blip2-opt-2.7b` (poor quality despite marketing claims)

---

## Provider Comparison

| Provider | Models | Setup | Cost | Offline | Customization |
|----------|--------|-------|------|---------|---------------|
| **OpenAI** | 3 models | API key required | Pay per use | ‚ùå No | Limited |
| **Ollama** | 6+ models | Local install | Free | ‚úÖ Yes | High |
| **Hugging Face** | 6 models | Auto-download | Free | ‚úÖ Yes | High |

---

## Ollama Models (Local, Free)

### üåô **moondream:latest** - *Best Starter Model*
- **Size**: ~1.7GB
- **Speed**: ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê Very Fast
- **Quality**: ‚≠ê‚≠ê‚≠ê‚≠ê Good
- **Prompt Following**: ‚≠ê‚≠ê‚≠ê Basic
- **Best for**: Quick captions, batch processing, learning the app
- **Strengths**: Lightweight, fast startup, low resource usage

### ü¶ô **llava:latest** - *Classic Vision Model*
- **Size**: ~4.7GB
- **Speed**: ‚≠ê‚≠ê‚≠ê‚≠ê Fast
- **Quality**: ‚≠ê‚≠ê‚≠ê‚≠ê Good
- **Prompt Following**: ‚≠ê‚≠ê‚≠ê‚≠ê Good
- **Best for**: General descriptions, reliable performance
- **Strengths**: Well-established, stable, good balance

### ü¶ô **llava-llama3:latest** - *Recommended General Use*
- **Size**: ~4.7GB
- **Speed**: ‚≠ê‚≠ê‚≠ê‚≠ê Fast
- **Quality**: ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê Excellent
- **Prompt Following**: ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê Excellent
- **Best for**: Most users, detailed descriptions, custom prompts
- **Strengths**: Latest Llama 3 base, excellent instruction following

### ü¶ô **llama3.2-vision:latest** - *Highest Quality Local*
- **Size**: ~7.9GB
- **Speed**: ‚≠ê‚≠ê‚≠ê Moderate
- **Quality**: ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê Excellent
- **Prompt Following**: ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê Excellent
- **Best for**: High-quality descriptions, complex prompts, professional use
- **Strengths**: Latest model, best local quality, great reasoning

### üíé **gemma2:latest** - *Efficient Alternative*
- **Size**: ~2.9GB
- **Speed**: ‚≠ê‚≠ê‚≠ê‚≠ê Fast
- **Quality**: ‚≠ê‚≠ê‚≠ê‚≠ê Good
- **Prompt Following**: ‚≠ê‚≠ê‚≠ê‚≠ê Good
- **Best for**: Resource-constrained systems, fast processing
- **Strengths**: Google's efficient architecture, good performance/size ratio

### üåü **mistral-small:latest** - *Balanced Option*
- **Size**: ~7.7GB
- **Speed**: ‚≠ê‚≠ê‚≠ê Moderate
- **Quality**: ‚≠ê‚≠ê‚≠ê‚≠ê Good
- **Prompt Following**: ‚≠ê‚≠ê‚≠ê‚≠ê Good
- **Best for**: Users wanting something different from Llama models
- **Strengths**: Mistral architecture, good multilingual support

---

## Hugging Face Models (Local, Free)

### üèÉ **microsoft/git-base-coco** - *Fastest Local*
- **Size**: ~1GB
- **Speed**: ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê Very Fast
- **Quality**: ‚≠ê‚≠ê‚≠ê Basic but honest
- **Prompt Following**: ‚≠ê None (ignores custom prompts)
- **Best for**: Quick captions, testing, batch processing thousands of images
- **Strengths**: Honest about what it does - simple captions, nothing more
- **Note**: Performs as well as blip2-opt for basic captions despite being 5x smaller

### üî• **Salesforce/blip2-opt-2.7b** - *DISAPPOINTING for Detailed Work*
- **Size**: ~5GB
- **Speed**: ‚≠ê‚≠ê‚≠ê‚≠ê Fast
- **Quality**: ‚≠ê‚≠ê Poor for narratives
- **Prompt Following**: ‚≠ê‚≠ê Very limited
- **Best for**: Only basic captioning (similar to git-base)
- **Avoid for**: Detailed descriptions, narrative prompts, professional use
- **Real Result**: "A train is seen at a station" for complex images with detailed prompts
- **Note**: ‚ö†Ô∏è **Not recommended** - performs barely better than git-base despite 5x the size

### üéØ **Salesforce/blip2-flan-t5-xl** - *Better Instructions*
- **Size**: ~11GB
- **Speed**: ‚≠ê‚≠ê‚≠ê Moderate
- **Quality**: ‚≠ê‚≠ê‚≠ê‚≠ê Good
- **Prompt Following**: ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê Excellent
- **Best for**: Complex instructions, detailed prompts, reasoning tasks
- **Strengths**: T5 language model, excellent instruction following

### üí¨ **openbmb/MiniCPM-V-2** - *Conversational*
- **Size**: ~8GB
- **Speed**: ‚≠ê‚≠ê‚≠ê Moderate
- **Quality**: ‚≠ê‚≠ê‚≠ê‚≠ê Good
- **Prompt Following**: ‚≠ê‚≠ê‚≠ê‚≠ê Good
- **Best for**: Conversational descriptions, interactive use
- **Strengths**: Chat-optimized, efficient architecture

### üéì **Salesforce/instructblip-vicuna-7b** - *Instruction Expert*
- **Size**: ~13GB
- **Speed**: ‚≠ê‚≠ê Slow
- **Quality**: ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê Excellent
- **Prompt Following**: ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê Excellent
- **Best for**: Complex instructions, professional descriptions, detailed analysis
- **Strengths**: Instruction-tuned, excellent for complex prompts

### ü¶ô **llava-hf/llava-1.5-7b-hf** - *Full Precision LLaVA*
- **Size**: ~13GB
- **Speed**: ‚≠ê‚≠ê Slow
- **Quality**: ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê Excellent
- **Prompt Following**: ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê Excellent
- **Best for**: When you want maximum quality LLaVA (vs compressed Ollama versions)
- **Note**: Similar to Ollama LLaVA but full precision - Ollama versions often better choice

---

## OpenAI Models (Cloud, Paid)

### üåü **gpt-4o** - *Best Overall*
- **Speed**: ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê Very Fast (cloud)
- **Quality**: ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê Excellent
- **Prompt Following**: ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê Excellent
- **Cost**: ~$0.01-0.05 per image
- **Best for**: Professional use, highest quality, complex reasoning

### üéØ **gpt-4o-mini** - *Balanced Cloud Option*
- **Speed**: ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê Very Fast (cloud)
- **Quality**: ‚≠ê‚≠ê‚≠ê‚≠ê Good
- **Prompt Following**: ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê Excellent
- **Cost**: ~$0.001-0.01 per image
- **Best for**: Cost-conscious users, good quality with lower cost

### ‚ö° **gpt-4-turbo** - *Legacy Option*
- **Speed**: ‚≠ê‚≠ê‚≠ê‚≠ê Fast (cloud)
- **Quality**: ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê Excellent
- **Prompt Following**: ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê Excellent
- **Cost**: ~$0.01-0.05 per image
- **Best for**: Users with existing workflows, similar to gpt-4o

---

## Use Case Recommendations

### üìö **Learning/Testing the App**
1. **Ollama**: `moondream:latest` (fast, lightweight)
2. **HF**: `microsoft/git-base-coco` (tiny download)

### üè† **Personal Use (Photos, Art)**
1. **Ollama**: `llava-llama3:latest` (excellent quality)
2. **Ollama**: `llama3.2-vision:latest` (highest quality free option)
3. **HF**: Wait for `instructblip` download (avoid blip2-opt)
4. **OpenAI**: `gpt-4o-mini` (if you don't mind paying)

### üíº **Professional/Commercial Use**
1. **OpenAI**: `gpt-4o` (highest quality)
2. **Ollama**: `llama3.2-vision:latest` (best free option)
3. **HF**: `Salesforce/instructblip-vicuna-7b` (instruction expert - downloading...)
4. **HF**: `microsoft/git-base-coco` (basic but reliable backup)

### ‚ö° **Batch Processing (Many Images)**
1. **Ollama**: `moondream:latest` (fastest)
2. **HF**: `microsoft/git-base-coco` (basic captions only)
3. **Ollama**: `llava:latest` (fast + quality)

### üé® **Creative/Artistic Descriptions**
1. **OpenAI**: `gpt-4o` (best creativity)
2. **Ollama**: `llava-llama3:latest` (great free option)
3. **HF**: `Salesforce/blip2-flan-t5-xl` (good instruction following)

### üíæ **Limited Resources (RAM/Storage)**
1. **Ollama**: `moondream:latest` (1.7GB)
2. **HF**: `microsoft/git-base-coco` (1GB)
3. **Ollama**: `gemma2:latest` (2.9GB)

### üåç **Offline/Air-gapped Systems**
- **Any Ollama or Hugging Face model** (all work offline once downloaded)
- **Not OpenAI** (requires internet connection)

---

## Performance Tips

### üöÄ **Speed Optimization**
- Use **Ollama models** for fastest processing
- **moondream** is fastest overall
- **git-base** is fastest for basic captions
- Close other applications to free up RAM/VRAM

### üíæ **Resource Management**
- **8GB RAM**: Stick to smaller models (moondream, git-base, blip2-opt)
- **16GB+ RAM**: Any model will work
- **GPU**: Dramatically speeds up Hugging Face models
- **CPU only**: Ollama models often better optimized

### üíø **Storage Considerations**
- **All models combined**: ~100GB+ storage needed
- **Start small**: Download 2-3 models initially
- **Pre-download**: Use download scripts for Hugging Face models
- **Cache location**: 
  - Ollama: `~/.ollama/models/`
  - HF: `~/.cache/huggingface/hub/`

### üîÑ **Model Switching**
- **No restart needed**: Switch between any downloaded models instantly
- **Memory**: Previous model unloads automatically
- **Ollama**: Models stay loaded in Ollama service (faster switching)
- **HF**: Models reload each time (slower but more memory-efficient)

---

## Troubleshooting

### ‚ùå **Model Not Appearing**
- **Ollama**: Run `ollama list` to verify model is downloaded
- **HF**: Restart app after downloading new models
- **OpenAI**: Check API key is set correctly

### üêå **Slow Performance**
- Try smaller models (moondream, git-base)
- Close other applications
- Use Ollama models (often more optimized)
- Check if GPU acceleration is working

### üí• **Out of Memory Errors**
- Use smaller models
- Close other applications
- For HF models: try CPU-only mode
- Restart the application

### üåê **Network Issues**
- **Pre-download HF models**: Use `python download_hf_models.py`
- **Ollama models**: Use `ollama pull model_name`
- **OpenAI**: Check internet connection and API key

### üö® **Performance Reality Check**
**Don't believe all marketing claims!** Our real-world testing found:
- `blip2-opt-2.7b` (5GB): Disappointing quality despite size - gave "A train is seen at a station" for detailed narrative prompt
- `git-base-coco` (1GB): Often performs as well as much larger models for basic descriptions
- Size ‚â† Quality: Bigger models don't always give better descriptions
- Download time matters: 5GB models may not justify the 30+ minute wait vs 1GB alternatives
- **Recommendation**: Start with `git-base-coco` or `moondream` before downloading huge models

---

## Future Model Support

The toolkit is designed to easily support new models as they become available:

- **Ollama**: New models appear automatically when available in Ollama
- **Hugging Face**: New vision models can be added to the provider
- **OpenAI**: New models can be added as OpenAI releases them

Stay tuned for updates that add support for new vision models and providers!

---

## Quick Reference Chart

| Model | Provider | Size | Speed | Quality | Prompts | Best For |
|-------|----------|------|-------|---------|---------|----------|
| moondream | Ollama | 1.7GB | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê | Beginners |
| git-base | HF | 1GB | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê | ‚≠ê | Quick captions |
| llava-llama3 | Ollama | 4.7GB | ‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | General use |
| blip2-opt | HF | 5GB | ‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê | Balanced |
| llama3.2-vision | Ollama | 7.9GB | ‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | Best free |
| gpt-4o | OpenAI | Cloud | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | Best overall |

---

*Last updated: September 2025 - Model landscape changes rapidly, check for updates!*