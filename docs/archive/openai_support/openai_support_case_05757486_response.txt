OPENAI SUPPORT CASE 05757486 - FOLLOW-UP RESPONSE

Date: February 15, 2026 19:08 UTC
Model: gpt-5-nano-2025-08-07
SDK: OpenAI Python SDK 2.16.0

===============================================================================
SUMMARY OF FINDINGS
===============================================================================

✓ Captured 2 failed examples + 1 successful example with full headers
✓ Captured raw HTTP request JSON sent over wire
❌ CRITICAL: temperature=0 test is IMPOSSIBLE - gpt-5-nano REJECTS it

Error when trying temperature=0:
```
{
  "error": {
    "message": "Unsupported value: 'temperature' does not support 0.0 with this 
model. Only the default (1) value is supported.",
    "type": "invalid_request_error",
    "param": "temperature",
    "code": "unsupported_value"
  }
}
```

This means gpt-5-nano ONLY accepts temperature=1 (default). We cannot test with 
temperature=0 as requested.

===============================================================================
FAILED EXAMPLE #1 (from previous capture)
===============================================================================

Timestamp: 2026-02-15 18:47:39 UTC
Response ID: chatcmpl-D9bRRC7ZECT7dKAn7xc68b0toPPaU
x-request-id: req_3849368524cb4723bff31ab1a17fe345
openai-processing-ms: 9593

RAW HTTP REQUEST JSON SENT OVER WIRE:
```json
{
  "model": "gpt-5-nano-2025-08-07",
  "max_completion_tokens": 1000,
  "messages": [{
    "role": "user",
    "content": [
      {"type": "text", "text": "Describe this image in detail."},
      {"type": "image_url", "image_url": {"url": "data:image/jpeg;base64,<BASE64_IMAGE_DATA>"}}
    ]
  }]
}
```

Note: Temperature NOT set (using model default of 1)
Note: No tools, functions, response_format, top_p parameters

RAW HTTP RESPONSE BODY:
```json
{
  "id": "chatcmpl-D9bRRC7ZECT7dKAn7xc68b0toPPaU",
  "model": "gpt-5-nano-2025-08-07",
  "choices": [{
    "message": {
      "role": "assistant",
      "content": "",
      "refusal": null,
      "annotations": []
    },
    "finish_reason": "length"
  }],
  "usage": {
    "completion_tokens": 1000,
    "completion_tokens_details": {
      "reasoning_tokens": 1000
    }
  }
}
```

KEY OBSERVATION: 
- finish_reason="length" (hit token limit)
- completion_tokens=1000 (all tokens consumed)
- reasoning_tokens=1000 (ALL tokens are reasoning)
- content="" (EMPTY - no actual output)

The model generates 1000 reasoning tokens internally but produces ZERO output text.

===============================================================================
FAILED EXAMPLE #2 (new capture)
===============================================================================

Timestamp: 2026-02-15 19:07:47.699 UTC
Response ID: chatcmpl-D9bl5TbbcOYLjvNWXR3FQFd3ht1Hq
x-request-id: req_0869f95f5cf34a6e9d45f92bf063a02a
openai-processing-ms: 5256

RAW HTTP REQUEST JSON SENT OVER WIRE:
```json
{
  "model": "gpt-5-nano-2025-08-07",
  "max_completion_tokens": 1000,
  "messages": [{
    "role": "user",
    "content": [
      {"type": "text", "text": "Describe this image in detail."},
      {"type": "image_url", "image_url": {"url": "data:image/jpeg;base64,<BASE64_IMAGE_DATA>"}}
    ]
  }]
}
```

RAW HTTP RESPONSE BODY:
```json
{
  "id": "chatcmpl-D9bl5TbbcOYLjvNWXR3FQFd3ht1Hq",
  "model": "gpt-5-nano-2025-08-07",
  "choices": [{
    "message": {
      "role": "assistant",
      "content": "",
      "refusal": null,
      "annotations": []
    },
    "finish_reason": "length"
  }],
  "usage": {
    "completion_tokens": 1000,
    "completion_tokens_details": {
      "reasoning_tokens": 1000
    }
  }
}
```

IDENTICAL PATTERN: reasoning_tokens=1000, content="", finish_reason="length"

===============================================================================
SUCCESSFUL EXAMPLE (for comparison)
===============================================================================

Timestamp: 2026-02-15 19:07:48.717 UTC
Response ID: chatcmpl-D9bl41o5SeUDh1EjMgd0NrTwJhF9c
x-request-id: req_afe5664ec4e54d2a85d33ee3d1b4e560
openai-processing-ms: 6725

RAW HTTP REQUEST JSON SENT OVER WIRE:
```json
{
  "model": "gpt-5-nano-2025-08-07",
  "max_completion_tokens": 1000,
  "messages": [{
    "role": "user",
    "content": [
      {"type": "text", "text": "Describe this image in detail."},
      {"type": "image_url", "image_url": {"url": "data:image/jpeg;base64,<BASE64_IMAGE_DATA>"}}
    ]
  }]
}
```

RAW HTTP RESPONSE BODY (excerpt):
```json
{
  "id": "chatcmpl-D9bl41o5SeUDh1EjMgd0NrTwJhF9c",
  "model": "gpt-5-nano-2025-08-07",
  "choices": [{
    "message": {
      "role": "assistant",
      "content": "This image features a red square centered on a white background. The square has clean, sharp edges and a solid, uniform red color throughout. The simplicity of the composition creates a minimalist aesthetic, with the red square standing out prominently against the plain white backdrop...",
      "refusal": null,
      "annotations": []
    },
    "finish_reason": "stop"
  }],
  "usage": {
    "completion_tokens": 650,
    "completion_tokens_details": {
      "reasoning_tokens": 0
    }
  }
}
```

KEY DIFFERENCE:
- finish_reason="stop" (natural completion)
- completion_tokens=650 (normal amount)
- reasoning_tokens=0 (no internal reasoning, direct output)
- content="..." (ACTUAL DESCRIPTION - 346 characters)

===============================================================================
ANALYSIS
===============================================================================

**Consistent pattern in failed responses:**
1. Model generates exactly 1000 reasoning tokens
2. All tokens consumed as reasoning, none as output
3. finish_reason="length" because reasoning hit max_completion_tokens
4. content field is empty string despite tokens being generated
5. HTTP 200 response (no error code)

**Successful responses:**
1. reasoning_tokens=0 (no internal reasoning used)
2. Content generated directly without reasoning phase
3. finish_reason="stop" (natural completion)

**Hypothesis:**
gpt-5-nano appears to enter a reasoning mode but fails to convert reasoning 
tokens into output text, exhausting the token budget on internal processing.

**Temperature constraint:**
gpt-5-nano does NOT support any temperature value except the default (1). 
Setting temperature=0, 0.7, or any other value results in HTTP 400 error.
Cannot perform requested temperature=0 consistency check.

**Observed failure rate:**
- Previous large batch: 27.8% empty (900/3,236)
- Test Phase 2: 39% empty (39/100)
- Recent capture: 25% empty (1/4 attempts)

===============================================================================
COMPLETE DATA FILE
===============================================================================

All examples with full headers, raw request JSON, and raw response bodies:
openai_support_case_05757486_complete.json

File includes:
- 2 failed examples with complete diagnostics
- 1 successful example for comparison
- All response headers (x-request-id, timestamps with timezone, openai-processing-ms)
- Exact raw HTTP request JSON structure
- Raw HTTP response bodies
- Parsed summaries

===============================================================================
QUESTIONS FOR OPENAI ENGINEERING
===============================================================================

1. Why does gpt-5-nano generate reasoning_tokens=1000 but output content=""?

2. Is this a known issue with the reasoning token output formatting?

3. Why is temperature locked to 1 for gpt-5-nano (no other values accepted)?

4. Should reasoning tokens be billed when they don't produce any output?

5. Is there a workaround or parameter adjustment to prevent this behavior?

===============================================================================
IMPACT
===============================================================================

~450,000 wasted tokens billed across production usage
27.8% failure rate making model unreliable for batch processing
All failed requests show identical reasoning_tokens=1000 + content="" pattern

Request credit/refund consideration for empty responses that consumed tokens.

===============================================================================

Complete data file attached: openai_support_case_05757486_complete.json
